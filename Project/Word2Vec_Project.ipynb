{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6eed90c-6c75-4d4d-8e9c-d26ef97f517f",
   "metadata": {},
   "source": [
    "# Word2Vec : Creating Word Embeddings with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf0eeec-d3ec-4c2c-897c-0bbdf3066151",
   "metadata": {},
   "source": [
    "References : \n",
    "* https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa\n",
    "* https://www.coursera.org/learn/probabilistic-models-in-nlp/home/week/4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac9c73c-640c-4a62-aa30-24405d784556",
   "metadata": {},
   "source": [
    "## Why do we need word embeddings ?\n",
    "\n",
    "When doing NLP, we are generally interested in being able to transform sentences or words into numeric representations, to then feed them to our algorithms and perform predictions.  Some simple methods of doing so include using term frequencies or n-grams among other things (counting the number of times a word appears in positive tweets vs. negative tweets for example)...  While these simple approaches can work quite well in some cases, sentences are essentially represented as \"Bags of Words\", meaning a lot of information is lost : sentence structure, semantics, what the usual context for a word is.  The word *cat* for example may be frequently accompanied by *a* or *the* to its left since it's a noun.  \n",
    "\n",
    "So how can we find more expressive numeric representations ?  This question motivated NLP researchers to create more sophisticated word representations, known as *word embeddings*.  These are *dense* vectors (vs. *sparse* vectors : vectors with high dimensionality where most of the values are 0s) and are now fundamental to any machine learning algorithm in NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fd423-1218-42b6-9045-f83f4c064fff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What principle do these word embeddings rely on ?\n",
    "\n",
    "Creating word embeddings relies on the idea that \"You shall know a word by the company it keeps\" (Firth, 1957). In [distributional semantics](https://en.wikipedia.org/wiki/Distributional_semantics#Distributional_Hypothesis), the distributional hypothesis tells us that words which occur and are used in the same context are semantically similar to one another.  The word vectors (embeddings) created take into account this contextual information, and ideally, the resulting vectors for words that have *similar contexts* end up in the same area of the vector space :\n",
    "\n",
    "<img src='vector_space_example.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c82bb15-1ff2-42d1-8f68-fed1e9386c41",
   "metadata": {},
   "source": [
    "## The Word2Vec Model\n",
    "\n",
    "This model was created by Google in 2013 and is a predictive deep learning based model :  given neighboring words, the neural network has to *predict* the word to be found at the center (this is only one of the possible architectures).\n",
    "\n",
    "\n",
    "Essentially, this model can leverage raw text (meaning no manual annotations needed), create a vocabulary of possible words and generate dense word embeddings for each word. We can even specify the size of the word embedding vectors, which makes the dimensionality of the vectors much lower than the high-dimensional sparse vectors built using traditional Bag of Words models.\n",
    "\n",
    "The model architecture we will be looking at is called the **Continuous Bag of Words Model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff704030-bc14-4be7-b0a6-c793005c3d11",
   "metadata": {},
   "source": [
    "## The Continuous Bag of Words Model (CBOW) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba3bf7-15d1-4113-809f-f24416957de4",
   "metadata": {},
   "source": [
    "To create word embeddings, you need a corpus and a learning algorithm, a simple neural net in this case.  The embeddings are a set of vectors that will be extracted from the neural net once it is trained, and are actually a *by-product* of the following task : the main objective of the CBOW model is to predict a missing word based on its surrounding words.  The intuition is that updating the values in the vectors (that we will be extracting) based on this task yields vectors that capture distributional semantics, ie. how these words are used in language, and make good word embedings.\n",
    "\n",
    "<div style='text-align:center;'><img src='Embedding_method.png'/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7205a-3ac5-4ad7-84e3-b170b02ff3c8",
   "metadata": {},
   "source": [
    "The CBOW model architecture tries to predict the current target word (the center word) based on context words (the surrounding words). Let's take a simple example :\n",
    "> **“the quick brown fox jumps over the lazy dog”**.\n",
    "\n",
    "The sentence will be transformed into a series of examples for the model to train on : each example will consist of a (context_window, target_word) tuple.  Considering a context window of size $C=2$ (2 words to the left, 2 to the right, so 4 total) we would obtain :\n",
    "> Ex. 1 : (*[the, quick, fox, jumps]*, brown)  \n",
    "> Ex. 2 : (*[quick, brown, jumps, over]*, fox)  \n",
    "> Etc ...\n",
    "\n",
    "The neural net's task will be to predict the target word based on the context window words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e16ca46-8d17-4917-93f9-756699d07969",
   "metadata": {},
   "source": [
    "This means we can model this problem as a classification task such that we take in the context words as our input (X) and try to predict the target word (Y) out of all the possible words in the vocabulary.  This is essentialy a *multiclass* classification task (only 1 of the possible classes is correct), where a class is equivalent to a word in the vocabulary.  Here is an overview of the process : \n",
    "\n",
    "<div style='text-align:center;'><img src=\"CBOW_overview.png\"/></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f57ea-a2eb-43f4-9f29-badef4ade538",
   "metadata": {},
   "source": [
    "## Implementing the CBOW model\n",
    "\n",
    "Using text from Shakespeare's plays, you will implement the CBOW model from scratch, using pytorch to simplify the creation of the network architecture and training loop. The implementation will be divided into 4 parts: \n",
    "* **Building the corpus Vocab**\n",
    "* **Create the (context_window, target_word) examples**\n",
    "* **Build the neural network architecture**\n",
    "* **Train the model**\n",
    "* **Visualize the word embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df0d1b-a1ca-482a-a951-af8197f26b2d",
   "metadata": {},
   "source": [
    "### 1. Building the corpus Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b507afe8-8d4b-40f1-becb-81ee06da5c3c",
   "metadata": {},
   "source": [
    "In the next cell, the text has been loaded and split into tokens for you :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1b1cf6-51a2-446f-8b4e-5a62954a8984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 1084877 \n",
      " First 15 tokens :  ['this', 'is', 'the', 'etext', 'file', 'presented', 'by', 'project', 'gutenberg', '.', 'and', 'is', 'presented', 'in', 'cooperation']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re  \n",
    "\n",
    "# dataset link :https://ocw.mit.edu/ans7870/6/6.006/s08/lecturenotes/files/t8.shakespeare.txt \n",
    "# you can clean some the the metatext if you wish\n",
    "with open('Shakespeare.txt') as f:\n",
    "    text = f.read()   \n",
    "text = re.sub(r'[,!?;-]', '.',text)                                 #  Punktuations are replaced by .\n",
    "text = nltk.word_tokenize(text)                                     #  Tokenize string to words\n",
    "text = [ ch.lower() for ch in text if ch.isalpha() or ch == '.']    #  Lower case and drop non-alphabetical tokens\n",
    "print(\"Number of tokens:\", len(text), '\\n First 15 tokens : ', text[:15])  #  print data sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33b36f-b63a-4127-9a07-b86284a80491",
   "metadata": {},
   "source": [
    "Next you must :\n",
    "* Get the vocabulary and vocabulary size (the set() function can be useful...)\n",
    "* Create 2 dictionaries :\n",
    "    * word2idx => keys are words in vocab, values are a unique number you must attribute to each word\n",
    "    * idx2word => keys are a unique number, values are the corresponding word  \n",
    "    These dictionaries will allow you to map words in the vocab to unique numbers.  This is necessary as you will be feeding these numbers to the model, not the words directly.\n",
    "* Create the (context, target) example pairs and store them in a list called data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd682c6-2b2c-4f8f-b951-3a7639fe3616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size = None (should be equal to 7860)\n"
     ]
    }
   ],
   "source": [
    "# get the vocab and vocab length \n",
    "vocab = None\n",
    "vocab_size = None\n",
    "# sort the vocab alphabetically so everyone has the same indexes in the next cells (this is not strictly necessary)\n",
    "vocab = None\n",
    "print(f\"Vocab size = {vocab_size} (should be equal to 7860)\") # for small version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6492e7-adcc-453c-a05f-6cb59688c154",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m idx2word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# example of word to index mapping\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex of the word \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mking\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m :  \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43mword2idx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord which has index 3764:  \u001b[39m\u001b[38;5;124m\"\u001b[39m,idx2word[\u001b[38;5;241m3764\u001b[39m] )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# create the word2idx and idx2word dictionaries:\n",
    "word2idx = None\n",
    "idx2word = None\n",
    "# example of word to index mapping\n",
    "print(\"Index of the word 'king' :  \",word2idx['king'] )\n",
    "print(\"Word which has index 3764:  \",idx2word[3764] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1eaacbd-ba33-409f-8db7-f751e8540e81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 words : ['o', 'for', 'a', 'muse', 'of']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# check if it works for the first example   \u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst 5 words : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample n°1 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Going through the text, create a list of data examples, where each example consists of a (context, target) tuple.\n",
    "# The context can be represented as a list of the context words (2 before and 2 after)\n",
    "# You may start at word idx number 2 and end on the second to last word.\n",
    "\n",
    "data = []\n",
    "\n",
    "# loop to make training examples\n",
    "...\n",
    "\n",
    "\n",
    "# check if it works for the first example   \n",
    "print(f'first 5 words : {text[:5]}')\n",
    "print(f'example n°1 = {data[0]}')\n",
    "print(f'context = {data[0][0]}')\n",
    "print(f'target = {data[0][1]}')\n",
    "\n",
    "print(f'Number of examples : {len(data)}')\n",
    "# if this is too much data and training is too long on your computer, you can reduce the data size, removing some of the plays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5212cb5a",
   "metadata": {},
   "source": [
    "Expected output is :\n",
    "first 5 words : ['this', 'is', 'the', 'etext', 'file']  \n",
    "example n°1 = (['this', 'is', 'etext', 'file'], 'the')   \n",
    "context = ['this', 'is', 'etext', 'file']  \n",
    "target = the  \n",
    "Number of examples : 111692"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec393b3-ece5-4da9-8cc5-b0441d607c19",
   "metadata": {},
   "source": [
    "### 2. Building the neural net architecture with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac619996-e928-4a40-8d84-2978df3ca21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/get-started/locally/ to see how to install pytorch if you\n",
    "# are working on your own computer\n",
    "# googlecolab is always an option\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791fadcc-bc27-4bce-af1e-2c3e3d85a591",
   "metadata": {},
   "source": [
    "#### 2.1 Batching the data examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee541dd",
   "metadata": {},
   "source": [
    "In order to accelerate the training process, we can **batch** training examples together.  This means that instead of feeding the model 1 example at a time, we feed it 16 or 32 or 64 examples in one go. The batchsize is up to you and is generally a power of 2.  Pytorch's `Dataloader`class takes care of this for you.  It takes as arguments a pytorch `Dataset`(`TensorDataset` in this case) and a `batch_size`.  \n",
    "\n",
    "To be istantiated, the `TensorDataset` class here will take 2 arguments:\n",
    "* a pytorch tensor of inputs \n",
    "* a pytorch tensor of targets.  \n",
    "\n",
    "The inputs will be the contexts in the data list created above, except the tokens will have to be transformed into indexes (ie. integer values) for our neural net.  The targets will have to undergo the same treatment. Use the word2idx dictionary you created previously to get the corresponding indexes for each token.  Finally transform these lists into torch tensors by using `torch.tensor(list)` so they can be fed as arguments to the TorchDataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40663d34-8ccd-47df-996f-a77341c3c1d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      4\u001b[0m targets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(targets)\n\u001b[1;32m      8\u001b[0m dataset \u001b[38;5;241m=\u001b[39m TensorDataset(contexts, targets)\n\u001b[1;32m      9\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "contexts = torch.tensor\n",
    "targets = None\n",
    "\n",
    "assert len(contexts) == len(targets)\n",
    "\n",
    "dataset = TensorDataset(contexts, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7aa3aae6-2d8b-4c50-8826-fa2d69f3a755",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(contexts[:\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(targets[:\u001b[38;5;241m2\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(contexts.shape)\n",
    "print(contexts[:2])\n",
    "print(targets[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1271674-999e-4b20-a028-b336c336769a",
   "metadata": {},
   "source": [
    "Expected output:  \n",
    "\n",
    "torch.Size([111692, 4])  \n",
    "\n",
    "tensor([[6915, 3668, 2386, 2649],\n",
    "        [3668, 6873, 2649, 5201]])  \n",
    "        \n",
    "tensor([6873, 2386])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceefc1f-fd2f-45b0-813a-ae93d8f33ff1",
   "metadata": {},
   "source": [
    "#### 2.2 The Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f70a4d-8799-465c-8922-5698630f3995",
   "metadata": {},
   "source": [
    "Here is an overview of the model's architecture and how a single example flows through the layers :  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155fef6b-8fe4-4466-a7c6-5fbb1b2e7e18",
   "metadata": {},
   "source": [
    "<div style='text-align:center;'/><img src='Diapositive1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c5284-faed-47df-8d0a-7ef60c98a389",
   "metadata": {},
   "source": [
    "Take a look at the XOR notebook to see how a model class is created in pytorch (the init function and the forward function are the main components).\n",
    "\n",
    "You may add the `vocab_size` and number of embedding dimensions (`embedding_dim`) you want your embeddings to have (50 is a good choice) to the init parameters, so as to pass them in when you instantiate the model. \n",
    "\n",
    "Pytorch allows you to implement a special layer, called an embedding layer (`nn.Embedding`).  This special layer serves as a look-up table, mapping token indexes to vectors (**Embeddings**).  By default, the values in these vectors will be updated by the model with respect to our goal, which is to predict a token given the tokens surrouding it.  These 'trained' embeddings should therefore contain *distributional semantic* information that can be extracted from words appearing in the same context, which is what we're after.  Look at the the documentation to see what this layer takes as inputs : https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html\n",
    "\n",
    "Then, add an output layer.  Be aware of the input and output sizes of the layer.  Take a look at the notebook on the XOR problem to see how to create a linear layer in pytorch.\n",
    "\n",
    "The `forward` function deals with the flow of data through the model.  In this case, it takes as input a *batch* of context vectors.\n",
    "This batch must first go through the embedding layer which returns 4 vectors (1 for each word) of equal dimension for each example in the batch.  With a batch size of 128 and an embedding dimension of 50, the shape of the output of the `nn.Embedding` layer will be:  (128, 4, 50):  128 matrices (one per example in the batch) of 4 by 50 (one 50 dimensional vector per context word).\n",
    "\n",
    "\n",
    "For each example in the batch, you will compute the average these 4 vectors to obtain a single vector.  This means you must specify that the mean calculated has to be along dimension 1 (the one equal to 4).  This is why the model is called Continuous Bag of Words: we don’t consider the order of the context words when averaging their embeddings in this way; that information is lost.\n",
    "\n",
    "Finally, all that is left is to pass the batch of averaged vectors to the output layer !\n",
    "\n",
    "No need to use the softmax function as a final activation function here, this will be done automatically by the loss function in the training loop (cf. next section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe1dfcc6-3695-442f-921f-fc8dcbef10f3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the Neural Net\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCBOW\u001b[39;00m(\u001b[43m____\u001b[49m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ___, ____):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# inherit from nn.Module's init function\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         \n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# embedding layer\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the Neural Net (replace underscores and None)\n",
    "\n",
    "class CBOW(____):\n",
    "    def __init__(self, ___, ____):\n",
    "        \n",
    "        super().__init__()\n",
    "        # embedding layer\n",
    "        self.embeddings = None\n",
    "        # output layer\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, batch):\n",
    "        ...\n",
    "        # get the embeddings from the Embedding layer and average them along dim=1.\n",
    "        # use .shape to see what shape the batch has before and after going through \n",
    "        # each layer if you need to\n",
    "        \n",
    "       \n",
    "        # pass the batch through the output layer to get the logits and return the final output.\n",
    "        # the output should be a matrix with dimensions batch_size x vocab_size\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b56d320-7eba-4130-af1e-6224784cc9d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CBOW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#instantiate the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCBOW\u001b[49m(vocab_size, \n\u001b[1;32m      6\u001b[0m              embedding_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CBOW' is not defined"
     ]
    }
   ],
   "source": [
    "# set random seed to instantiate the model weights at random in a *reproducible* fashion\n",
    "# this means running this cell will reinitialize the embeddings to the same random initial values when you\n",
    "# try different hyperparameters\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#instantiate the model\n",
    "model = CBOW(vocab_size, \n",
    "             embedding_dim=50)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37598e-f290-4b7c-b884-3b83cb2f4321",
   "metadata": {},
   "source": [
    "Your model should look something like this :\n",
    "\n",
    "CBOW(  \n",
    "  (embeddings): Embedding(7860, 50)  \n",
    "  (output): Linear(in_features=50, out_features=7860, bias=True)  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fff8ba7-4287-4ef9-83c3-0d5d078fa26b",
   "metadata": {},
   "source": [
    "#### 2.3 Visualizing word vectors and similarities before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af9d26-23af-47e7-9879-92c2a9a1816c",
   "metadata": {},
   "source": [
    "To see if training the model on this task has had a desirable effect on the word vectors (which are randomly initialized when you instantiate the model), it can be useful to compare the vectors for certain words before vs. after training.  The code in the next 2 cells shows similarity measures between vectors and plots vectors in space after reducing their dimensionality to 2.\n",
    "\n",
    "The list of words used can be changed as you wish.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab062724-8b94-4c99-95e9-7c8da632da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eda1fbc-f595-47e5-9f3d-b920cbac5adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of words to study\n",
    "words = ['man', 'king', 'lord', 'woman', 'queen', 'lady']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1dfab6-8029-4f33-84a4-af787df9ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embeddings for the words, randomly initialized by the model\n",
    "embeddings_bef = np.array([model.embeddings(torch.tensor(word2idx[word],dtype=torch.long)).detach().numpy() \n",
    "                       for word in words]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1120dd2-0adc-497a-842f-24dbdbe1ecad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting the vectors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# In order to plot and visualize the vectors in 2D, we can use an algorithm called *Principal Component Analysis (PCA)* \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# to reduce the vectors' dimensions from 50 (or whichever dimension you chose) down to 2.  This can be easily done using `sklearn`.  \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the embeddings for the words, randomly initialized by the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([model\u001b[38;5;241m.\u001b[39membeddings(torch\u001b[38;5;241m.\u001b[39mtensor(word2idx[word],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m      7\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# perform PCA (reduce to 2 dimensions)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plotting the vectors\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# In order to plot and visualize the vectors in 2D, we can use an algorithm called *Principal Component Analysis (PCA)* \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# to reduce the vectors' dimensions from 50 (or whichever dimension you chose) down to 2.  This can be easily done using `sklearn`.  \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# the embeddings for the words, randomly initialized by the model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39membeddings(torch\u001b[38;5;241m.\u001b[39mtensor(word2idx[word],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m      7\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# perform PCA (reduce to 2 dimensions)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting the vectors\n",
    "# In order to plot and visualize the vectors in 2D, we can use an algorithm called *Principal Component Analysis (PCA)* \n",
    "# to reduce the vectors' dimensions from 50 (or whichever dimension you chose) down to 2.  This can be easily done using `sklearn`.  \n",
    "\n",
    "\n",
    "# perform PCA (reduce to 2 dimensions)\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(embeddings_bef)\n",
    "\n",
    "# plotting the 2D vectors\n",
    "plt.scatter(reduced[:,1], reduced[:, 0])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(reduced[i, 1], reduced[i, 0]))\n",
    "plt.show()\n",
    "# plt.savefig(\"plot.pdf\") # save fig to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44074d49-d540-4b0d-9a20-51e80c1189e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# the embeddings for the words, randomly initialized by the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([model\u001b[38;5;241m.\u001b[39membeddings(torch\u001b[38;5;241m.\u001b[39mtensor(word2idx[word],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m      3\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      4\u001b[0m dot_similarity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(embeddings, embeddings\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      5\u001b[0m norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# the embeddings for the words, randomly initialized by the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39membeddings(torch\u001b[38;5;241m.\u001b[39mtensor(word2idx[word],dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong))\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy() \n\u001b[1;32m      3\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words])\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      4\u001b[0m dot_similarity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(embeddings, embeddings\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      5\u001b[0m norms \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# This code creates a heatmap showing the cosine similarity between each of the words in the list\n",
    "\n",
    "# compute cosine simil between words\n",
    "dot_similarity = np.dot(embeddings_bef, embeddings_bef.T)\n",
    "norms = np.linalg.norm(embeddings_bef, axis=1)\n",
    "dot_similarity /= np.outer(norms, norms)\n",
    "\n",
    "# create heatmap (top half has been masked for more clarity, since it shows the same scores as the bottom half)\n",
    "mask = np.zeros_like(dot_similarity)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(dot_similarity,\n",
    "            xticklabels=words,\n",
    "            yticklabels=words,\n",
    "            annot=True,\n",
    "            mask=mask,\n",
    "            cmap='viridis')\n",
    "# plt.savefig(\"heatmap.pdf\") # save fig to pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2e7021-d626-4120-b783-34763c8c082f",
   "metadata": {},
   "source": [
    "#### **Question** : \n",
    "\n",
    "How do you think the cosine similarity scores will/should change after training ?  In the plot, how would you expect the vectors to move ?  Which word vectors should end up closer/farther ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759c59f-e064-4d7d-8da0-1ffa743e1c4b",
   "metadata": {},
   "source": [
    "#### 2.4 Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449c12b-df5c-484e-8596-c75d2df88b91",
   "metadata": {},
   "source": [
    "Start by selecting the appropriate loss function and optimizer.  You may use `nn.CrossEntropyLoss()` as a loss function and `torch.optim.SGD`for the optimizer.  This optimizer is an implementation of the Gradient Descent algorithm and takes as arguments `model.parameters()`, the model's parameters, and `lr` the learning rate, which can be set to 0.1 when using batches of 128 (experiment with different values here).  \n",
    "\n",
    "Next you can run the model for 150-200 epochs or until you find little to no change between current_loss and prev_loss.  This should be able to run on your computer, but if not just copy import the notebook into colab.  The fact that we divided the training data into batches means each epoch should take a few secs instead of several minutes.  (Batching is usually used in conjunction with a GPU but can speed things up even on a CPU, which is what we are using here.)\n",
    "\n",
    "*NOTE: until you reset the parameters by re-instantiating the model, the training loop will continue from where it left off. If you stop and then retstart the cell below, you will continue training the parameters from the last epoch.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a08957-edaf-4501-a939-5254f62ee363",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# the dataloader is a generator object, it produces a batch of contexts and targets if you iterate over it.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m context, target \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataloader\u001b[49m:\n\u001b[1;32m     16\u001b[0m     \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# get the logits\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# calculate the loss by passing the logits and targets to the loss_function\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "loss_function = None\n",
    "optimizer = None\n",
    "epochs = 150\n",
    "\n",
    "#TRAINING\n",
    "# around 4s per epoch on my machine (small version)\n",
    "# you can track the time passed per epoch by decommenting the time1 line and the print(time.time...) at the end.\n",
    "for epoch in range(epochs):\n",
    "    #time1 = time.time()\n",
    "    \n",
    "    # initiliaze the total_loss for each epoch to 0\n",
    "    total_loss = None\n",
    "\n",
    "    # the dataloader is a generator object, it produces a batch of contexts and targets when you iterate over it.\n",
    "    for context, target in dataloader:\n",
    "        \n",
    "        # get the logits\n",
    "        logits = None\n",
    "        \n",
    "        # calculate the loss by passing the logits and targets to the loss_function\n",
    "        loss = None\n",
    "        \n",
    "        # add the loss value to the total_loss (use loss.item() to get the value as a standard number vs a pytorch tensor)\n",
    "        total_loss += None\n",
    "\n",
    "        \n",
    "        # optimize the network weights using the three steps seen in the XOR notebook\n",
    "        ...\n",
    "    \n",
    "    # track the loss by printing it every 10 epochs (replace with 1 to see the time passed per epoch)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch {epoch+1} : {total_loss}')\n",
    "    \n",
    "    #print(time.time()-time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294ea31-27e7-4b61-9b1e-6b0e29215f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your trained model for easier experimentation\n",
    "torch.save(model.state_dict(), f'cbow_model_{epochs}.pth') # add num of epochs to know which model this is for example\n",
    "\n",
    "# load your trained model whenever you want with\n",
    "model = CBOW(vocab_size, embedding_dim=50) # reset the model\n",
    "model.load_state_dict(torch.load('cbow_model_150.pth')) # load the saved weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5324aef8-3f6a-41fc-badd-9357670650c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.5 Visualizing word vectors and similarities after training\n",
    "\n",
    "Using the same list of words as before, the next cells show the new similarities and plot the new word vectors.  What has changed ? Do the results seem to verify your hypotheses ?  \n",
    "How do you think the results could be improved ?\n",
    "\n",
    "Try changing the hyperparameters to see if they have any impact.  These include :\n",
    "\n",
    "* number of embedding dimensions (ie. size of the embeddings)\n",
    "* learning rate\n",
    "* number of epochs\n",
    "* batch size (optionally)\n",
    "\n",
    "Training word vectors requires large amounts of text.  This project is a toy example, so do not be discouraged if differences are small... Try to still look for anything noteworthy.  How would you expect the vectors to move ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecab8dd-320d-4e7c-9d70-cb87192bf4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_aft = np.array([model.embeddings(torch.tensor(word2idx[word],dtype=torch.long)).detach().numpy() \n",
    "                       for word in words]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22e90dfa-1fdb-4d1d-9aae-e38b7258d5b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0064013  4.596994 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reduced = pca.fit_transform(embeddings_aft)\n",
    "print(reduced[0])\n",
    "\n",
    "plt.scatter(reduced[:,1], reduced[:, 0])\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(reduced[i, 1], reduced[i, 0]))\n",
    "plt.show()\n",
    "# plt.savefig(\"plot.pdf\") # save fig to pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25c308-ebfa-4b2f-8d7b-eab54471afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_similarity = np.dot(embeddings_aft, embeddings_aft.T)\n",
    "norms = np.linalg.norm(embeddings_aft, axis=1)\n",
    "dot_similarity /= np.outer(norms, norms)\n",
    "\n",
    "mask = np.zeros_like(dot_similarity)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(dot_similarity,\n",
    "            xticklabels=words,\n",
    "            yticklabels=words,\n",
    "            annot=True,\n",
    "            mask=mask,\n",
    "            cmap='viridis')\n",
    "# plt.savefig(\"heatmap.pdf\") # save fig to pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
